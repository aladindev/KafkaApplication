
kafka를 중앙에 배치함으로써 소스 어플리케이션과 타깃 어플리케이션 사이의
의존드를 최소화하여 커플링을 '완화' 할 수 있다.

기존에 1:1 매칭으로 개발하고 운영하던 데이터 파이프라인은
커플링으로 인해 한쪽의 이슈가 다른 한쪽의 어플리케이션에 영향을 미치곤 했지만
카프카는 이러한 의존도를 낮춰줄 수 있었다.

이제 소스 어플리케이션에서 생성되는 데이터는 어느 타깃 어플리케이션으로
보낼 것인지 고민하지 않고 카프카로 넣으면 된다.

카프카 내부에 데이터가 저장되는 파티션의 동작은
FIFO(First In First Out) 방식의 큐 자료구조와
유사하다.

큐에 데이터를 보내는 것이 '프로듀서(Producer)'
큐에서 데이터를 가져가는 것이 '컨슈머(Consumer)' 이다!

카프카를 통해 전달할 수 있는 데이터 포맷은 사실상 제한이 없다.
직렬화, 역직렬화를 통해 ByteArray로 통신하기 때문에
자바에서 선언 가능한 모든 객체를 지원한다!

영속성이란,
데이터를 생성한 프로그램이 종료되더라도 사라지지 않은 데이터의 특성
카프카는 다른 메시징 플랫폼과 다르게 전송받은 데이터를
메모리에 저장하지 않고 파일 시스템에 저장한다.

고가용성
3개 이상의 서버들로 운영되는 카프카 클러스터는 일부 서버에
장애가 발생하더라도 무중단으로 안전하고 지속적으로 데이터를 처리할 수 있다.
클러스터로 이루어진 카프카는 데이터의 복제(replication)를 통해 고가용성의
특징을 가지게 되었다.

프로듀서로 전송받은 데이터를 여러 브로커 중 1대의 브로커에만
저장하는 것이 아니라 또 다른 브로커에도 저장하는 것이다.
한 브로커에 장애가 발생하더라도 복제된 데이터가 나머지 브로커에
저장되어 있으므로 저장된 데이터를 기준으로 지속적으로 데이터 처리가 가능한 것이다.
이에 더하여 서버를 직접 운영하는 온프레미스(on-premise) 환경의 서버 랙 또는
퍼블릭 클라우드의 리전 단위 장애에도 데이터를 안전하게 복제할 수 있는
브로커 옵션들이 준비되어 있다.

카프카 클러스터를 1, 2대가 아닌 3대 이상의 브로커들로 구성해야 하는 이유
카프카 클러스터를 구축할 때 브로커 개수의 제한은 없지만, 안전하게 운영하기 위해
최소 3대 이상의 브로커로 클러스터를 구성할 것을 추천한다.

1대 운영 시 브로커의 장애는 곧 서비스의 장애
2대 운영 시 1대 브로커에서 장애가 발생해도
나머지 한 대가 살아있으므로 정상운영되지만
브로커 간에 데이터가 복제(replication)되는 시간 차이로 일부 데이터
유실 가능

배치데이터 : 초, 분, 시간, 일 등으로 한정된(Bounded) 기간 단위 데이터를 뜻한다.
배치 데이터를 일괄 처리(batch processing)하는 것이 특징이다.

스트림 데이터 : 한정되지 않은(unbounded) 데이터로 시작 데이터와 끝 데이터가
명확히 정해지지 않은 데이터를 뜻한다.

카프카 브로커 : 카프카 클라이언트와 데이터를 주고 받기 위해
사용하는 주체이자, 데이터를 분산 저장하여 장애가 발생하더라도
안전하게 사용할 수 있도록 도와주는 어플리케이션이다.
하나의 서버에는 한 개의 카프카 브로커 프로세스가 실행된다.
카프카 브로커 서버 1대로도 기본 기능이 실행되지만
데이터를 안전하게 보관하고 처리하기 위해 3대 이상의 브로커 서버를
1개의 클러스터로 묶어서 운영한다.
카프카 클러스터로 묶인 브로커들은 프로듀서가 보낸 데이터를
안전하게 분산하고 저장하고 복제하는 역할을 수행한다.


AWS EC2 프리티어 인스턴스
인스턴스 내에 카프카, 주키퍼 설치


토픽 생성
kafka-topics.sh 를 통해 토픽 관련 명령을 실행할 수 있다.
--create 옵션을 사용하여 토픽을 생성할 수 있다.

개발 편의를 위해
/ets/hosts 파일에 서버 인스턴스 아이피를 alias 지정할 수 있음.


Zookeeper 실행
bin/zookeeper-server-start.sh -daemon ./config/zookeeper.properties

-daemon은 백그라운드 실행 인자

Kafka 서버 실행
bin/kafka-server-start.sh -daemon ./config/server.properties

실행 순서는
주키퍼 -> kafka 안그러면 에러 !!


bin/kafka-topics.sh -- 토픽 관련 커맨드 쉘 파일
bin/kafka-console-produce.sh -- 프로듀서 관련 커멘드 쉘파일
(데이터를 카프카로 전달한다. 프로듀서의 역할)
bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 --topic
(카프카의 데이터를 읽는다. 컨슈머 역할)
이때 필수옵션으로 --bootstrap-server에 카프카 클러스터 정보,
--topic에 토픽 이름이 필요하다. 추가로 --from-beginning 옵션을 주면
토픽에 저장된 가장 처음 데이터로부터 출력한다.
bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092
--topic hello.kafka
--property pring.key=true
--property key.separator="-"
--from-beginning

kafka-verifiable-producer, consumer.sh
kafka-verifiable로 시작하는 2개의 스크립트를 사용하면
String 타입 메세지 값을 코드 없이 주고 받을 수 있다.
카프카 클러스터 설치가 완료된 이후에 토픽에 데이터를 전송하여 간단한
네트워크 통신 테스트를 할 때 유용하다.



3. 카프카 기본 개념

카프카 브로커 : 카프카 클라이언트와 데이터를 주고 받기 위해
             사용하는 주체이자, 데이터를 분산 저장하여 장애가 발생하더라도 안전하게
             사용할 수 있도록 도와주는 애플리케이션.
             하나의 서버에는 한 개의 카프카 브로커 프로세스가 실행됨.

