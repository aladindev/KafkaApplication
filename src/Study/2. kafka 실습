
kafka를 중앙에 배치함으로써 소스 어플리케이션과 타깃 어플리케이션 사이의
의존드를 최소화하여 커플링을 '완화' 할 수 있다.

기존에 1:1 매칭으로 개발하고 운영하던 데이터 파이프라인은
커플링으로 인해 한쪽의 이슈가 다른 한쪽의 어플리케이션에 영향을 미치곤 했지만
카프카는 이러한 의존도를 낮춰줄 수 있었다.

이제 소스 어플리케이션에서 생성되는 데이터는 어느 타깃 어플리케이션으로
보낼 것인지 고민하지 않고 카프카로 넣으면 된다.

카프카 내부에 데이터가 저장되는 파티션의 동작은
FIFO(First In First Out) 방식의 큐 자료구조와
유사하다.

큐에 데이터를 보내는 것이 '프로듀서(Producer)'
큐에서 데이터를 가져가는 것이 '컨슈머(Consumer)' 이다!

카프카를 통해 전달할 수 있는 데이터 포맷은 사실상 제한이 없다.
직렬화, 역직렬화를 통해 ByteArray로 통신하기 때문에
자바에서 선언 가능한 모든 객체를 지원한다!
  
영속성이란,
데이터를 생성한 프로그램이 종료되더라도 사라지지 않은 데이터의 특성
카프카는 다른 메시징 플랫폼과 다르게 전송받은 데이터를
메모리에 저장하지 않고 파일 시스템에 저장한다.

고가용성
3개 이상의 서버들로 운영되는 카프카 클러스터는 일부 서버에
장애가 발생하더라도 무중단으로 안전하고 지속적으로 데이터를 처리할 수 있다.
클러스터로 이루어진 카프카는 데이터의 복제(replication)를 통해 고가용성의
특징을 가지게 되었다.

프로듀서로 전송받은 데이터를 여러 브로커 중 1대의 브로커에만
저장하는 것이 아니라 또 다른 브로커에도 저장하는 것이다.
한 브로커에 장애가 발생하더라도 복제된 데이터가 나머지 브로커에
저장되어 있으므로 저장된 데이터를 기준으로 지속적으로 데이터 처리가 가능한 것이다.
이에 더하여 서버를 직접 운영하는 온프레미스(on-premise) 환경의 서버 랙 또는
퍼블릭 클라우드의 리전 단위 장애에도 데이터를 안전하게 복제할 수 있는
브로커 옵션들이 준비되어 있다.

카프카 클러스터를 1, 2대가 아닌 3대 이상의 브로커들로 구성해야 하는 이유
카프카 클러스터를 구축할 때 브로커 개수의 제한은 없지만, 안전하게 운영하기 위해
최소 3대 이상의 브로커로 클러스터를 구성할 것을 추천한다.

1대 운영 시 브로커의 장애는 곧 서비스의 장애
2대 운영 시 1대 브로커에서 장애가 발생해도
나머지 한 대가 살아있으므로 정상운영되지만
브로커 간에 데이터가 복제(replication)되는 시간 차이로 일부 데이터
유실 가능

배치데이터 : 초, 분, 시간, 일 등으로 한정된(Bounded) 기간 단위 데이터를 뜻한다.
배치 데이터를 일괄 처리(batch processing)하는 것이 특징이다.

스트림 데이터 : 한정되지 않은(unbounded) 데이터로 시작 데이터와 끝 데이터가
명확히 정해지지 않은 데이터를 뜻한다.

카프카 브로커 : 카프카 클라이언트와 데이터를 주고 받기 위해
사용하는 주체이자, 데이터를 분산 저장하여 장애가 발생하더라도
안전하게 사용할 수 있도록 도와주는 어플리케이션이다.
하나의 서버에는 한 개의 카프카 브로커 프로세스가 실행된다.
카프카 브로커 서버 1대로도 기본 기능이 실행되지만
데이터를 안전하게 보관하고 처리하기 위해 3대 이상의 브로커 서버를
1개의 클러스터로 묶어서 운영한다.
카프카 클러스터로 묶인 브로커들은 프로듀서가 보낸 데이터를
안전하게 분산하고 저장하고 복제하는 역할을 수행한다.


AWS EC2 프리티어 인스턴스
인스턴스 내에 카프카, 주키퍼 설치


토픽 생성
kafka-topics.sh 를 통해 토픽 관련 명령을 실행할 수 있다.
--create 옵션을 사용하여 토픽을 생성할 수 있다.

개발 편의를 위해
/ets/hosts 파일에 서버 인스턴스 아이피를 alias 지정할 수 있음.


Zookeeper 실행
bin/zookeeper-server-start.sh -daemon ./config/zookeeper.properties

-daemon은 백그라운드 실행 인자

Kafka 서버 실행
bin/kafka-server-start.sh -daemon ./config/server.properties

실행 순서는
주키퍼 -> kafka 안그러면 에러 !!


bin/kafka-topics.sh -- 토픽 관련 커맨드 쉘 파일
bin/kafka-console-produce.sh -- 프로듀서 관련 커멘드 쉘파일
(데이터를 카프카로 전달한다. 프로듀서의 역할)
bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 --topic
(카프카의 데이터를 읽는다. 컨슈머 역할)
이때 필수옵션으로 --bootstrap-server에 카프카 클러스터 정보,
--topic에 토픽 이름이 필요하다. 추가로 --from-beginning 옵션을 주면
토픽에 저장된 가장 처음 데이터로부터 출력한다.
bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092
--topic hello.kafka
--property pring.key=true
--property key.separator="-"
--from-beginning

kafka-verifiable-producer, consumer.sh
kafka-verifiable로 시작하는 2개의 스크립트를 사용하면
String 타입 메세지 값을 코드 없이 주고 받을 수 있다.
카프카 클러스터 설치가 완료된 이후에 토픽에 데이터를 전송하여 간단한
네트워크 통신 테스트를 할 때 유용하다.



3. 카프카 기본 개념

카프카 브로커 : 카프카 클라이언트와 데이터를 주고 받기 위해
             사용하는 주체이자, 데이터를 분산 저장하여 장애가 발생하더라도 안전하게
             사용할 수 있도록 도와주는 애플리케이션.
             하나의 서버에는 한 개의 카프카 브로커 프로세스가 실행됨.

안정적인 운영을 위해 브로커 서버는 최소 3대 이상으로 권장
프로듀서와 데이터를 주고 받는 리더 파티션
나머지 팔로워 파티션으로 구성

Controller : 클러스터의 다수 브로커 중 한 대가 컨트롤러의 역할 수행
            - 다른 브로커들의 상태 체크
            - 브로커가 클러스터에서 빠지는 경우 브로커에 존재하는 리더 파티션을 재분배
            - 카프카는 지속적으로 데이터를 처리 및 replication 해야 하므로
              브로커의 상태가 비정상이라면 빠르게 클러스터(3대 이상 브로커 묶음)에 빼내는 것이 중요.

데이터 삭제 : 카프카는 다른 메시징 플랫폼과 다르게 컨슈머가 데이터를 가져가더라도
           토픽의 데이터는 삭제되지 않는다. 또한 컨슈머나 프로듀서가 데이터 삭제를 요청할 수도 없다.
           오직 브로커만이 삭제할 수 있다.
           데이터 삭제 > 파일 단위로 이뤄짐.(단위 : log segment)

컨슈머 offset 저장 : 컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고
                  이 파티션의 어느 레코드까지 가져갔는지 확인하기 위해 옵셋 커밋

coordinator : 클러스터의 다수 브로커 중 한 대는 코디네이터의 역할을 수행한다.
              코디네이터는 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록
              분배하는 역할을 한다.
              파티션을 컨슈머로 재할당하는 과정 : 리밸런스(rebalance)

zookeeper : 카프카의 메타데이터를 관리하는 데에 사용된다.

토픽 : 카프카에서 데이터를 구분하기 위해 사용하는 단위이다.
      토픽은 1개 이상의 파티션을 소유한다.
      파티션에는 프로듀서가 보낸 데이터가 적재되는데
      이 데이터를 레코드라고 부른다.

파티션 : 카프카 병렬처리의 핵심!
       그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있도록 매칭된다.
       큐 자료구조와 비슷한 구조로 동작
       다만 큐와 다르게 데이터를 삭제하지는 않는다!!

프로듀서 중요 개념!
프로듀서는 카프카 브로커로 데이터를 전송할 때 내부적으로
파티셔너, 배치 생성 단계를 거친다.

토폴로지(topology) : 토폴로지란 2개 이상의 노드들과 선으로 이루어진 집합을 뜻한다.
                   토폴로지의 종류로는 링형(ring), 트리형(tree), 성형(star) 등이 있는데
                   스트림즈에서 사용하는 토폴로지는 트리 형태와 유사하다.
                   카프카 스트림즈에서는 트리 형태와 유사함.

카프카 스트림즈에서 토폴로지를 이루는 노드를 하나의 'Processor'라고 부르고
노드와 노드를 이은 선을 'stream'이라고 부른다.
프로세서에는 소스 프로세서, 스트림 프로세서, 싱크 프로세서 3가지가 있다.
소스 프로세서는 데이터를 처리하기 위해 최초로 선언 해야하는 노드로
하나 이상의 토픽에서 데이터를 가져오는 역할을 한다.

코파티셔닝(co-partitioning) : 조인을 하는 2개 데이터의 파티션 개수가 동일하고
                           파티셔닝 전략을 동일하게 맞추는 작업이다.
                           파티션 개수가 동일하고 파티셔닝 전략이 같은 경우에는 동일한
                           메세지 키를 가진 데이터가 동일한 태스크에 들어가는 것을 보장한다.


Streams DSL - KTable과 KStream Join()
대부분의 DB는 정적으로 저장된 데이터를 조인하여 사용했지만
카프카에서는 실시간으로 들어오는 데이터들을 조인할 수 있다.
사용자의 이벤트 데이터를 데이터베이스에 저장하지 않고도
조인하여 스트리밍 처리할 수 있다는 장점이 있다.
이를 통해 이벤트 기반 스트리밍 데이터 파이프라인을 구성할 수 있는 것이다.

둘은 반드시 코파티셔닝 되어 있어야 한다!!!!!!
안그러면 TopologyException 발생

카프카 커넥스
producer 역할을 수행하는 Source Connector
consumer 역할을 수행하는 Sing Connector

카프카 미러메이커2(Kafka- MirrorMaker2)








